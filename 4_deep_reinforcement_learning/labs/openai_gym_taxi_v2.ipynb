{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"openai_gym_taxi_v2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMOgZC9zdGf9K2oKKVLPD1Y"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"X8iI0xFUgBp9","executionInfo":{"status":"ok","timestamp":1603099343013,"user_tz":-60,"elapsed":838,"user":{"displayName":"Quant Furs","photoUrl":"","userId":"11918726383869251504"}}},"source":["import gym\n","import numpy as np\n","import random\n","from IPython.display import clear_output\n","\n","env = gym.make('Taxi-v3').env\n","\n","q_table = np.zeros([env.observation_space.n, env.action_space.n])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwGQ0TJPJXnf","executionInfo":{"status":"ok","timestamp":1603099496419,"user_tz":-60,"elapsed":105708,"user":{"displayName":"Quant Furs","photoUrl":"","userId":"11918726383869251504"}},"outputId":"92140d33-b5cb-4974-b193-be53bc877007","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#hyperparameters\n","alpha = 0.1\n","gamma = 0.6\n","epsilon = 0.1\n","\n","#plotting metrics\n","all_epochs = []\n","all_penalites = []\n","\n","for i in range(1, 100001):\n","  state = env.reset()\n","  epochs, penalties, reward, = 0, 0, 0\n","  done = False\n","\n","  while not done:\n","    if random.uniform(0, 1) < epsilon:\n","      action = env.action_space.sample() #explore action space\n","    else:\n","      action = np.argmax(q_table[state]) #exploit learned values\n","\n","    next_state, reward, done, info = env.step(action)\n","\n","    old_value = q_table[state, action]\n","    next_max = np.max(q_table[next_state])\n","\n","    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n","    q_table[state, action] = new_value\n","\n","    if reward == -10:\n","      penalties += 1\n","\n","    state = next_state\n","    epochs += 1\n","\n","  if i % 100 == 0:\n","    clear_output(wait=True)\n","    print(f'Episode: {i}')\n","\n","  print('Training finished.\\n')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Episode: 100000\n","Training finished.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GhZfAcN6LTDE","executionInfo":{"status":"ok","timestamp":1603099735622,"user_tz":-60,"elapsed":877,"user":{"displayName":"Quant Furs","photoUrl":"","userId":"11918726383869251504"}},"outputId":"c8934713-83cd-4d03-fb33-4a53c5f82cb9","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#evaluation\n","\n","total_epochs, total_penalties = 0, 0\n","episodes = 100\n","\n","for _ in range(episodes):\n","  state = env.reset()\n","  epochs, penalties, reward = 0, 0, 0\n","\n","  done = False\n","\n","  while not done:\n","    action = np.argmax(q_table[state])\n","    state, reward, done, info = env.step(action)\n","\n","    if reward == -10:\n","      penalties += 1\n","\n","    epochs += 1\n","\n","  total_penalties += penalties\n","  total_epochs += epochs\n","\n","print(f'Results after {episodes} episodes:')\n","print(f'Average timesteps per episode: {total_epochs / episodes}')\n","print(f'Average penalties per episode: {total_penalties / episodes}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Results after 100 episodes:\n","Average timesteps per episode: 12.94\n","Average penalties per episode: 0.0\n"],"name":"stdout"}]}]}